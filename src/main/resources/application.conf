akka {
  event-handlers = ["akka.event.slf4j.Slf4jEventHandler"]
  loglevel = "DEBUG"
  actor {
    provider = "akka.cluster.ClusterActorRefProvider"
  }

  remote {
    log-remote-lifecycle-events = off
    netty.tcp {
      hostname = "127.0.0.1"
      port = 0
    }
  }

  cluster {
    seed-nodes = [
      "akka.tcp://ClusterSystem@127.0.0.1:2551",
      "akka.tcp://ClusterSystem@127.0.0.1:2552"]

    auto-down-unreachable-after = 10s
  }

  debug {
    # enable function of LoggingReceive, which is to log any received message at
    # DEBUG level
    receive = on

    autoreceive = on
  }
  extensions = ["akka.contrib.pattern.DistributedPubSubExtension"]


  persistence {
    journal {
      plugin = "akka-persistence-sql-async.journal"
  //    plugin = "dynamodb-journal"
      //plugin = "akka.persistence.journal.inmem"
        max-mesage-batch-size = 4000
    }
    snapshot-store.plugin = "akka-persistence-sql-async.snapshot-store"
  }


akka-persistence-sql-async {
  journal.class = "akka.persistence.journal.sqlasync.PostgreSQLAsyncWriteJournal"
  snapshot-store.class = "akka.persistence.snapshot.sqlasync.PostgreSQLSnapshotStore"

  user = "root"
  pass = "password"
  url = "jdbc:postgresql://..."
  max-pool-size = 64 # total connection count
  wait-queue-capacity = 10000 # If query cannot be executed soon, it wait in the queue and will be executed later.
  journal-table-name = "akka_journal"
  snapshot-table-name = "akka_snapshot"
}
}

dynamodb-journal {
    journal-table =  "akkajournal"
    operation-timeout =  10 seconds
    endpoint =  "https://dynamodb.eu-west-1.amazonaws.com"
    sequence-shards = 1
}

spray.can.host-connector.max-connections = 600